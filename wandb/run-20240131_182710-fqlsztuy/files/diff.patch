diff --git a/.github/workflows/ci.yaml b/.github/workflows/ci.yaml
index f64271a..efbb2b8 100644
--- a/.github/workflows/ci.yaml
+++ b/.github/workflows/ci.yaml
@@ -2,7 +2,7 @@ name: ci demo
 run-name: ci demo
 on: [push]
 jobs:
-    my-first-job:
+    sample-job:
         runs-on: ubuntu-latest
         steps:
         - uses: actions/checkout@v3
diff --git a/.gitignore b/.gitignore
index ee6c03a..0c3fe91 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,2 +1,3 @@
 higgsenv/
-notebooks/analysis.ipynb
\ No newline at end of file
+notebooks/analysis.ipynb
+.env
\ No newline at end of file
diff --git a/Procfile b/Procfile
deleted file mode 100644
index 18459f8..0000000
--- a/Procfile
+++ /dev/null
@@ -1 +0,0 @@
-web: sh setup.sh && streamlit run --server.port $PORT app.py
\ No newline at end of file
diff --git a/Train.py b/Train.py
deleted file mode 100644
index e69de29..0000000
diff --git a/modelling.py b/modelling.py
index 354c1c3..d559a22 100644
--- a/modelling.py
+++ b/modelling.py
@@ -25,7 +25,7 @@ def preprocess(df):
     y = df['Label']
     return X, y
 
-def fit_score(X, y):
+def fit_score(X, y, **kwargs):
     """Fit, cross-validate and print metrics
 
     Args:
@@ -36,8 +36,9 @@ def fit_score(X, y):
         xgboost.sklearn.XGBClassifier: A baseline XGB classifier
     """
     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
-    
-    xgb_model = XGBClassifier(objective='binary:logistic', random_state=42)
+
+    xgb_model = XGBClassifier(objective='binary:logistic', random_state=42, **kwargs)
+    # xgb_model.set_params(params)
     xgb_model.fit(X_train, y_train)
 
     precision_scorer = make_scorer(precision_score)
@@ -53,27 +54,29 @@ def fit_score(X, y):
     y_pred = xgb_model.predict(X_test)
     precision = precision_score(y_test, y_pred)
     print(f'\nTest data Precision: {precision}')
+    
+    precision_class_0 = precision_score(y_test, y_pred, labels=[0], average=None)[0]
+    precision_class_1 = precision_score(y_test, y_pred, labels=[1], average=None)[0]
 
-    # Print confusion matrix
-    conf_matrix = confusion_matrix(y_test, y_pred)
-    print("Confusion Matrix:")
-    print(conf_matrix)
+    metrics = {'Average Precision': precision_scores.mean(), 'Test data Precision': precision, 'Precision of Background event': precision_class_0,  'Precision of Signal event': precision_class_1}
 
-    # Print classification report
-    class_report = classification_report(y_test, y_pred)
-    print("\nClassification Report:")
-    print(class_report)
-    
-    return xgb_model
+    return xgb_model, metrics
 
 def save(model, path):
     with open(path, 'wb') as model_file:
         pickle.dump(model, model_file)
 
 
+params = {
+        "eta" : 0.1,
+        "max_depth": 6,
+        "nthread" : 4,
+    }
+
 df = pd.read_csv('data/training.zip', low_memory=False)
 X, y = preprocess(df)
-model = fit_score(X, y)
+model, metrics = fit_score(X, y, **params)
+print(metrics)
 save(model, 'models/Baseline_XGB.pkl')
 
 #-----------------------------------------------------------------------------------------------------#
@@ -85,7 +88,7 @@ save(model, 'models/Baseline_XGB.pkl')
 columns = ['DER_mass_MMC', 'DER_mass_vis', 'DER_mass_transverse_met_lep', 'PRI_tau_pt', 'PRI_met_sumet', 'DER_mass_jet_jet', 'Weight', 'Label']
 df = df[columns]
 X, y = preprocess(df)
-infer_model = fit_score(X, y) 
+infer_model = fit_score(X, y)
 save(infer_model, 'models/Base_infer_XGB.pkl')
 
 
diff --git a/models/Base_infer_XGB.pkl b/models/Base_infer_XGB.pkl
index 742a1d1..e9b4e70 100644
Binary files a/models/Base_infer_XGB.pkl and b/models/Base_infer_XGB.pkl differ
diff --git a/models/Baseline_XGB.pkl b/models/Baseline_XGB.pkl
index ef19c5a..9aa190c 100644
Binary files a/models/Baseline_XGB.pkl and b/models/Baseline_XGB.pkl differ
