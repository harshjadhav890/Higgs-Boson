{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a128f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823e6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Label'] = label_encoder.fit_transform(df['Label'])\n",
    "    X = df.drop(['Label', 'Weight'], axis=1)\n",
    "    y = df['Label']\n",
    "    return X, y\n",
    "\n",
    "def fit_score(X, y, **kwargs):\n",
    "    \"\"\"Fit, cross-validate and print metrics\n",
    "    Args:\n",
    "        X (pandas.core.frame.DataFrame): Independent variables\n",
    "        y (pandas.core.frame.DataFrame): Label to predict\n",
    "    Returns:\n",
    "        xgboost.sklearn.XGBClassifier: A baseline XGB classifier\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    xgb_model = XGBClassifier(objective='binary:logistic', random_state=42, **kwargs)\n",
    "    # xgb_model.set_params(params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    precision_scorer = make_scorer(precision_score)\n",
    "    k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    precision_scores = cross_val_score(xgb_model, X_train, y_train, cv=k_fold, scoring=precision_scorer)\n",
    "    for i, precision in enumerate(precision_scores):\n",
    "        print(f'Fold {i+1}: Precision = {precision}')\n",
    "    # Print the average precision across all folds\n",
    "    print(f'\\nAverage Precision: {precision_scores.mean()}')\n",
    "    # Make predictions on the test data\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f'\\nTest data Precision: {precision}')\n",
    "    # Print confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    # Print classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "    metrics = {'Average Precision': precision_scores.mean(), 'Test data Precision': precision, 'Confusion Matrix': conf_matrix, 'Classification Report': class_report}\n",
    "    return xgb_model, metrics\n",
    "\n",
    "def save(model, path):\n",
    "    with open(path, 'wb') as model_file:\n",
    "        pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eabd89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"eta\" : 0.1,\n",
    "        \"max_depth\": 6,\n",
    "        \"nthread\" : 4,\n",
    "    }\n",
    "\n",
    "df = pd.read_csv('data/training.zip', low_memory=False)\n",
    "X, y = preprocess(df)\n",
    "model, metrics = fit_score(X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1c9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31576588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.xgboost import WandbCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from modelling import preprocess, fit_score, save\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "## uncomment when running locally. left out to be used by github workflows\n",
    "\n",
    "load_dotenv()\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "# Logging into wandb\n",
    "\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "# import fastparquet\n",
    "\n",
    "parquet_file_path = 'data/preprocessed_data.parquet'\n",
    "# Read the Parquet file into a Pandas DataFrame using fastparquet\n",
    "\n",
    "df = pd.read_parquet(parquet_file_path, engine='fastparquet')\n",
    "# setup parameters for xgboost\n",
    "\n",
    "params = {\n",
    "    \"eta\" : 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"nthread\" : 4,\n",
    "}\n",
    "# Train and save the model locally\n",
    "\n",
    "X, y = preprocess(df)\n",
    "model, metrics = fit_score(X, y, **params)\n",
    "save(model, 'models/Tuned_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d6bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Artifact QXJ0aWZhY3Q6NzA5MTgyNzk1>"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbafb7bb408a42f799d68edaaf379448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888904896, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\vscode\\TMLC\\Higgs_Boson\\wandb\\run-20240131_174939-zsbj9rdc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson/runs/zsbj9rdc' target=\"_blank\">giddy-planet-3</a></strong> to <a href='https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson' target=\"_blank\">https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson/runs/zsbj9rdc' target=\"_blank\">https://wandb.ai/harsh-ajay-jadhav/Higgs-Boson/runs/zsbj9rdc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"Higgs-Boson\",\n",
    "    config=params,\n",
    "    job_type = 'train_model'\n",
    ")\n",
    "\n",
    "run.use_artifact('harsh-ajay-jadhav/Higgs-Boson/df_preprocessed:latest', type='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed0e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = wandb.Artifact(\n",
    "        name= 'Tuned_model',\n",
    "        type='model'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441bdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model(model_name, local_model_path, wandb_data_path, metrics=None):\n",
    "    run = wandb.init(\n",
    "        project=\"Higgs-Boson\",\n",
    "        config=params,\n",
    "        job_type = 'train_model'\n",
    "    )\n",
    "    run.use_artifact(wandb_data_path, type='dataset')\n",
    "    model_artifact = wandb.Artifact(\n",
    "            name=model_name,\n",
    "            type='model'\n",
    "        )\n",
    "    model_artifact.add_file(local_path=local_model_path)\n",
    "    run.log_artifact(model_artifact)\n",
    "    if metrics is not None:\n",
    "        run.log(metrics)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31328523",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = 'models/Tuned_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47edf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model(model_name, local_model_path, wandb_data_path = 'harsh-ajay-jadhav/Higgs-Boson/df_preprocessed:v0', metrics=None):\n",
    "    run = wandb.init(\n",
    "        project=\"Higgs-Boson\",\n",
    "        config=params,\n",
    "        job_type = 'train_model'\n",
    "    )\n",
    "    run.use_artifact(wandb_data_path, type='dataset')\n",
    "    model_artifact = wandb.Artifact(\n",
    "            name=model_name,\n",
    "            type='model'\n",
    "        )\n",
    "    model_artifact.add_file(local_path=local_model_path)\n",
    "    run.log_artifact(model_artifact)\n",
    "    if metrics is not None:\n",
    "        run.log(metrics)\n",
    "    wandb.finish()\n",
    "\n",
    "log_model('tuned_model', local_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
